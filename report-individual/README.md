# Technical Report - Individual Submission

This folder contains individual technical reports detailing the AI agent solution built by each student's group.

## Requirements

### File Format
- **Format:** Markdown (`.md`)
- **Naming:** `YYYY-FamilyName-FirstName.md` (ASCII characters only)
- **License:** Include license declaration (CC-BY-4.0 recommended)

### Content Requirements

Each student must write an **individual** technical report describing the solution built by their group. While you worked as a team, this report is your personal documentation demonstrating your understanding.

Your report must include:

| Section | Description |
|---------|-------------|
| **Title & Author** | Project title, your name, group members |
| **Abstract** | Brief summary (100-150 words) |
| **Introduction** | Problem context and objectives |
| **System Architecture** | Overall design of your AI agent system |
| **Implementation** | Key components, tools, and methods used |
| **Results** | What the system achieves, with examples |
| **Discussion** | Challenges, limitations, lessons learned |
| **Conclusion** | Summary and potential future work |
| **References** | Sources cited |

---

## Grading Criteria

The technical report contributes to your individual assessment. It is evaluated on:

| Criterion | Weight | Description |
|-----------|--------|-------------|
| Technical Accuracy | 30% | Correct description of system architecture and implementation |
| Depth of Understanding | 30% | Demonstrates personal comprehension beyond surface-level |
| Completeness | 20% | All required sections present with sufficient detail |
| Clarity & Organization | 15% | Logical structure, clear explanations, good formatting |
| Writing Quality | 5% | Grammar, spelling, professional tone |

---

## Example Technical Report

```markdown
# Technical Report: HRV-Based Fatigue Detection Agent

**Author:** 2026-Chen-Wei
**Group Members:** Chen Wei, Lin MeiLing, Wang XiaoMing
**License:** CC-BY-4.0

## Abstract

This report describes an AI agent system developed to automatically analyze
heart rate variability (HRV) data for stress and fatigue detection. The system
uses Claude Opus 4.5 as an orchestrator to coordinate ECG signal processing,
HRV feature extraction, Random Forest classification, and AI-generated report
interpretation into an autonomous workflow. Trained on the SWELL-KW dataset
(25 subjects, knowledge work stress conditions) and evaluated on held-out
subjects S22-S25, our agent achieves 78.4% accuracy (AUC-ROC: 0.84) in
distinguishing stressed from neutral states. The LF/HF ratio emerged as the
most discriminative HRV feature. The complete pipeline processes a 3-minute
ECG window in under 9 seconds, including natural language interpretation of
results generated by Claude Opus 4.5.

## Introduction

Fatigue is a significant factor in workplace accidents and reduced productivity.
Traditional fatigue assessment relies on subjective questionnaires or expensive
equipment. Heart rate variability (HRV) provides an objective, non-invasive
biomarker that correlates with autonomic nervous system activity and fatigue
levels.

This project aimed to develop an AI agent that:
1. Processes raw ECG signals automatically
2. Extracts relevant HRV features
3. Classifies fatigue state
4. Generates interpretable reports

## System Architecture

Our system follows a modular agent architecture with a central Orchestrator coordinating
specialized tools:

```
┌──────────────────────────────────────────────────────────────────────────┐
│                         HRV Analysis Agent System                         │
├──────────────────────────────────────────────────────────────────────────┤
│                                                                           │
│  ┌──────────────┐      ┌──────────────┐      ┌──────────────┐            │
│  │ <<agent>>    │      │ <<tool>>     │      │ <<tool>>     │            │
│  │              │─────▶│              │─────▶│              │            │
│  │ Orchestrator │      │ ECG Loader   │      │ Signal       │            │
│  │              │      │              │      │ Processor    │            │
│  └──────┬───────┘      └──────────────┘      └──────┬───────┘            │
│         │                                           │                     │
│         │                                           ▼                     │
│         │              ┌──────────────┐      ┌──────────────┐            │
│         │              │ <<model>>    │      │ <<tool>>     │            │
│         │              │              │◀─────│              │            │
│         │              │ Classifier   │      │ Feature      │            │
│         │              │              │      │ Extractor    │            │
│         │              └──────┬───────┘      └──────┬───────┘            │
│         │                     │                     │                     │
│         │                     │    ┌────────────────┘                     │
│         │                     │    │  (features + prediction)             │
│         │                     ▼    ▼                                      │
│         │              ┌──────────────┐      ┌──────────────┐            │
│         │              │ <<tool>>     │      │ <<artifact>> │            │
│         └─────────────▶│              │─────▶│              │            │
│                        │ Report       │      │ PDF Report   │            │
│                        │ Generator    │      │              │            │
│                        └──────────────┘      └──────────────┘            │
│                                                                           │
└──────────────────────────────────────────────────────────────────────────┘

External:
┌──────────────┐
│ <<database>> │
│ File System  │  ECG Data Files (.txt)
└──────────────┘
```

### Component Descriptions

| Component | Type | Description |
|-----------|------|-------------|
| **Orchestrator** | Agent | Central controller that manages workflow execution, coordinates tool calls, maintains state, and handles errors |
| **ECG Loader** | Tool | Reads ECG data from file system, validates format, returns NumPy array |
| **Signal Processor** | Tool | Applies bandpass filtering, removes baseline wander, detects R-peaks |
| **Feature Extractor** | Tool | Calculates time-domain and frequency-domain HRV metrics from R-R intervals |
| **Classifier** | Model | Random Forest model that predicts fatigue state from HRV features |
| **Report Generator** | Tool | Compiles results into formatted PDF report with visualizations |

## Data

### Dataset: SWELL-KW (Stress and User Modeling)

We used the [SWELL-KW dataset](https://www.kaggle.com/datasets/qiriro/swell-heart-rate-variability-hrv) for training
and evaluating our fatigue/stress classification model.

**Source:** Koldijk, S., Sappelli, M., Verberne, S., Neerincx, M., & Kraaij, W. (2014).
The SWELL Knowledge Work Dataset for Stress and User Modeling Research. ICMI 2014.
Available at: http://cs.ru.nl/~skoldijk/SWELL-KW/Dataset.html

**Dataset Description:**
- **Subjects:** 25 participants performing knowledge work tasks
- **Conditions:** 3 stress conditions (neutral, time pressure, interruptions) + relaxation
- **Duration:** ~3 hours per participant
- **Signals:** ECG (for HRV extraction), skin conductance, facial expressions, body posture
- **Labels:** NASA-TLX task load, mental effort (RSME), emotion (SAM), perceived stress

**HRV Features Available:**
- Time-domain: SDNN, RMSSD, pNN50, mean RR
- Frequency-domain: LF power, HF power, LF/HF ratio
- Non-linear: SD1, SD2, sample entropy

### Train/Test Split

| Split | Subjects | Samples | Purpose |
|-------|----------|---------|---------|
| **Training** | S01-S17 (68%) | ~3,400 windows | Model training with 5-fold CV |
| **Validation** | S18-S21 (16%) | ~800 windows | Hyperparameter tuning |
| **Test** | S22-S25 (16%) | ~800 windows | Final evaluation (held out) |

**Rationale:** Subject-wise split ensures the model generalizes to unseen individuals,
not just unseen time windows from training subjects.

### Alternative Dataset: WESAD

For validation across different populations, we also tested on [WESAD](https://archive.ics.uci.edu/ml/datasets/WESAD+(Wearable+Stress+and+Affect+Detection)):
- **Subjects:** 15 participants
- **Signals:** ECG (700 Hz), EDA, EMG, respiration, temperature
- **Conditions:** Neutral, stress (Trier Social Stress Test), amusement
- **Use:** Cross-dataset validation to assess generalizability

## Tools Used

- **Agent Framework:** Anthropic Claude Code (claude-opus-4-5-20251101) with MCP tools
- **Programming Language:** Python 3.11
- **Signal Processing:** SciPy 1.11.0 (filtering, spectral analysis)
- **Data Handling:** NumPy 1.24.0, Pandas 2.0.0
- **Machine Learning:** scikit-learn 1.3.0 (Random Forest classifier)
- **Visualization:** Matplotlib 3.7.0
- **Development Environment:** VS Code with Claude Code extension

The agent was configured to autonomously execute the signal processing pipeline,
calling Python functions as tools and managing state between processing steps.

## Implementation

### Orchestrator

**Tools:** Anthropic Claude Opus 4.5 (claude-opus-4-5-20251101), Python asyncio

**Functionality:**
- Central controller that manages the entire HRV analysis workflow
- Coordinates sequential tool execution: load → process → extract → classify → report
- Maintains state between tool calls and handles data passing
- Implements error handling and retry logic for failed operations
- Provides natural language interface for user interaction

**Key Code:**
```python
import anthropic
import json

class HRVAnalysisOrchestrator:
    def __init__(self):
        self.client = anthropic.Anthropic()
        self.model = "claude-opus-4-5-20251101"
        self.tools = self._define_tools()
        self.state = {}

    def _define_tools(self) -> list:
        """Define available tools for the agent."""
        return [
            {"name": "load_ecg", "description": "Load ECG data from a text file", ...},
            {"name": "process_signal", "description": "Apply filtering and detect R-peaks", ...},
            {"name": "extract_features", "description": "Calculate HRV metrics", ...},
            {"name": "classify_fatigue", "description": "Predict fatigue state", ...},
            {"name": "generate_report", "description": "Create PDF report", ...}
        ]

    def run(self, ecg_file: str, output_path: str) -> str:
        """Execute the full HRV analysis pipeline."""
        messages = [{"role": "user", "content": f"Analyze '{ecg_file}' for fatigue..."}]

        while True:
            response = self.client.messages.create(
                model=self.model, max_tokens=4096, tools=self.tools, messages=messages
            )
            if response.stop_reason == "end_turn":
                return self._extract_final_response(response)

            # Process tool calls and append results
            for block in response.content:
                if block.type == "tool_use":
                    result = self._execute_tool(block.name, block.input)
                    ...  # Append tool results to messages

    def _execute_tool(self, name: str, inputs: dict) -> dict:
        """Execute a tool and store results in state."""
        if name == "load_ecg":
            self.state["ecg_data"] = load_ecg(**inputs)
        elif name == "process_signal":
            self.state["processed"] = process_signal(self.state["ecg_data"])
        ...  # Handle other tools similarly
        return result
```

### ECG Loader

**Tools:** NumPy 1.24.0, Python pathlib

**Functionality:**
- Accepts `.txt` files with single-column ECG amplitude values
- Configurable sampling rate (default: 500 Hz)
- Validates data integrity and handles missing values

**Key Code:**
```python
import numpy as np
from pathlib import Path

def load_ecg(file_path: str, sampling_rate: int = 500) -> dict:
    """Load ECG data from text file."""
    path = Path(file_path)
    if not path.exists():
        raise FileNotFoundError(f"ECG file not found: {file_path}")

    data = np.loadtxt(path)
    if data.ndim != 1:
        raise ValueError("Expected single-column ECG data")

    return {
        "signal": data,
        "sampling_rate": sampling_rate,
        "duration_sec": len(data) / sampling_rate
    }
```

### Signal Processor

**Tools:** SciPy 1.11.0 (signal module), NumPy 1.24.0

**Functionality:**
- Bandpass filter: 0.5-40 Hz (4th order Butterworth)
- Baseline wander removal using high-pass filtering
- R-peak detection using Pan-Tompkins algorithm

**Key Code:**
```python
from scipy.signal import butter, filtfilt, find_peaks

def bandpass_filter(signal: np.ndarray, fs: int,
                    lowcut: float = 0.5, highcut: float = 40.0) -> np.ndarray:
    """Apply bandpass filter to ECG signal."""
    nyquist = fs / 2
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(4, [low, high], btype='band')
    return filtfilt(b, a, signal)

def detect_r_peaks(signal: np.ndarray, fs: int) -> np.ndarray:
    """Detect R-peaks using derivative-based method."""
    # Differentiate and square
    diff_signal = np.diff(signal)
    squared = diff_signal ** 2

    # Moving average
    window_size = int(0.15 * fs)
    integrated = np.convolve(squared, np.ones(window_size)/window_size, mode='same')

    # Find peaks with minimum distance
    min_distance = int(0.2 * fs)  # 200ms minimum RR interval
    peaks, _ = find_peaks(integrated, distance=min_distance, height=np.mean(integrated))

    return peaks
```

### Feature Extractor

**Tools:** NumPy 1.24.0, SciPy 1.11.0 (signal.welch for spectral analysis)

**Functionality:**

*Time-domain features:*
- SDNN (Standard deviation of NN intervals)
- RMSSD (Root mean square of successive differences)
- pNN50 (Percentage of successive intervals > 50ms)

*Frequency-domain features:*
- LF power (0.04-0.15 Hz)
- HF power (0.15-0.4 Hz)
- LF/HF ratio

**Key Code:**
```python
from scipy.signal import welch

def extract_hrv_features(rr_intervals: np.ndarray, fs: int = 4) -> dict:
    """Extract HRV features from RR intervals."""
    # Time-domain features
    sdnn = np.std(rr_intervals, ddof=1)
    diff_rr = np.diff(rr_intervals)
    rmssd = np.sqrt(np.mean(diff_rr ** 2))
    pnn50 = np.sum(np.abs(diff_rr) > 50) / len(diff_rr) * 100

    # Frequency-domain features (Welch's method)
    rr_interp = np.interp(
        np.arange(0, len(rr_intervals), 1/fs),
        np.arange(len(rr_intervals)),
        rr_intervals
    )
    freqs, psd = welch(rr_interp, fs=fs, nperseg=256)

    lf_mask = (freqs >= 0.04) & (freqs < 0.15)
    hf_mask = (freqs >= 0.15) & (freqs < 0.4)
    lf_power = np.trapz(psd[lf_mask], freqs[lf_mask])
    hf_power = np.trapz(psd[hf_mask], freqs[hf_mask])

    return {
        "sdnn": sdnn, "rmssd": rmssd, "pnn50": pnn50,
        "lf_power": lf_power, "hf_power": hf_power,
        "lf_hf_ratio": lf_power / hf_power if hf_power > 0 else np.nan
    }
```

### Classifier

**Tools:** scikit-learn 1.3.0 (RandomForestClassifier), joblib

**Functionality:**
- Random Forest classifier with 100 estimators
- Trained on labeled HRV dataset (fatigued vs. rested)
- 5-fold cross-validation during development
- Outputs: fatigue probability, confidence based on tree agreement

**Key Code:**
```python
from sklearn.ensemble import RandomForestClassifier
import joblib

def train_classifier(X_train: np.ndarray, y_train: np.ndarray) -> RandomForestClassifier:
    """Train fatigue classifier."""
    clf = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42
    )
    clf.fit(X_train, y_train)
    return clf

def predict_fatigue(clf: RandomForestClassifier, features: dict) -> dict:
    """Predict fatigue state from HRV features."""
    X = np.array([[features["sdnn"], features["rmssd"], features["pnn50"],
                   features["lf_power"], features["hf_power"], features["lf_hf_ratio"]]])

    proba = clf.predict_proba(X)[0]
    prediction = clf.predict(X)[0]

    return {
        "prediction": "Fatigued" if prediction == 1 else "Rested",
        "confidence": max(proba),
        "fatigue_probability": proba[1]
    }
```

### Report Generator

**Tools:** Anthropic Claude Opus 4.5 (claude-opus-4-5-20251101), Matplotlib 3.7.0, ReportLab 4.0

**Functionality:**
- Generates PDF report with HRV metrics summary and visualizations
- Uses Claude Opus 4.5 to write interpretive text for Discussion and Conclusion sections
- Provides clinical context for HRV metrics based on published reference ranges
- Generates personalized recommendations based on fatigue classification

**Key Code:**
```python
import anthropic
import matplotlib.pyplot as plt
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Image, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from datetime import datetime
import io

def generate_interpretation(features: dict, prediction: dict) -> dict:
    """Use Claude Opus 4.5 to generate report text interpretation."""
    client = anthropic.Anthropic()

    prompt = f"""Analyze these HRV metrics and fatigue classification results.
Write a Discussion and Conclusion section for a clinical report.

HRV Metrics:
- SDNN: {features['sdnn']:.2f} ms (normal range: 50-100 ms)
- RMSSD: {features['rmssd']:.2f} ms (normal range: 20-50 ms)
- pNN50: {features['pnn50']:.2f}% (normal range: 10-25%)
- LF/HF Ratio: {features['lf_hf_ratio']:.2f} (normal range: 1.0-2.0)

Classification Result:
- Prediction: {prediction['prediction']}
- Confidence: {prediction['confidence']:.1%}
- Fatigue Probability: {prediction['fatigue_probability']:.1%}

Provide:
1. Discussion (2-3 paragraphs): Interpret the HRV metrics in clinical context,
   explain what the values indicate about autonomic nervous system balance,
   and discuss the classification result.
2. Conclusion (1 paragraph): Summarize findings and provide recommendations.

Use professional medical report language. Be specific about the metrics."""

    response = client.messages.create(
        model="claude-opus-4-5-20251101",
        max_tokens=1024,
        messages=[{"role": "user", "content": prompt}]
    )

    # Parse response into sections
    text = response.content[0].text
    sections = text.split("Conclusion")

    return {
        "discussion": sections[0].replace("Discussion", "").strip(),
        "conclusion": sections[1].strip() if len(sections) > 1 else ""
    }

def generate_report(ecg_data: dict, features: dict, prediction: dict,
                    output_path: str) -> str:
    """Generate PDF report with HRV analysis and AI-written interpretation."""

    # Generate AI interpretation
    interpretation = generate_interpretation(features, prediction)

    # Create 2x2 visualization (ECG signal, HRV metrics, frequency power, classification pie)
    fig, axes = plt.subplots(2, 2, figsize=(10, 8))
    ...  # Plot ECG, bar charts for HRV metrics, pie chart for classification
    plt.savefig(img_buffer, format='png', dpi=150)

    # Build PDF with ReportLab: title, visualizations, AI-generated discussion/conclusion
    doc = SimpleDocTemplate(output_path, pagesize=A4)
    story = [Paragraph("HRV Analysis Report", styles['Title']),
             Image(img_buffer), Paragraph(interpretation["discussion"]),
             Paragraph(interpretation["conclusion"])]
    doc.build(story)
    return output_path
```

### Agent Learning and Adaptation

**Tools:** Anthropic Claude Opus 4.5, scikit-learn, JSON logging

The agent incorporates several learning and adaptation mechanisms:

#### 1. Prompt Refinement Through Feedback

The Orchestrator improves its task execution by learning from user feedback:

```python
def update_system_prompt(self, feedback: str, outcome: str):
    """Refine system prompt based on user feedback."""
    refinement_prompt = f"""
    Previous outcome: {outcome}
    User feedback: {feedback}

    Based on this feedback, suggest improvements to the analysis workflow.
    Focus on: parameter adjustments, additional checks, or modified interpretations.
    """

    response = self.client.messages.create(
        model=self.model,
        max_tokens=512,
        messages=[{"role": "user", "content": refinement_prompt}]
    )

    # Store learned improvements for future runs
    self.learned_refinements.append(response.content[0].text)
```

#### 2. Classifier Retraining with New Data

The system supports incremental learning when new labeled data becomes available:

```python
def retrain_classifier(self, new_features: np.ndarray, new_labels: np.ndarray):
    """Incrementally update classifier with new labeled samples."""
    # Combine with existing training data
    X_combined = np.vstack([self.X_train, new_features])
    y_combined = np.hstack([self.y_train, new_labels])

    # Retrain with updated dataset
    self.classifier.fit(X_combined, y_combined)

    # Update stored training data
    self.X_train = X_combined
    self.y_train = y_combined

    # Log retraining event
    logging.info(f"Classifier retrained with {len(new_labels)} new samples")
```

#### 3. Adaptive Threshold Calibration

The system adjusts classification thresholds based on population characteristics:

```python
def calibrate_thresholds(self, population_hrv_stats: dict):
    """Adapt fatigue thresholds to specific population norms."""
    # Adjust based on population baseline
    age_factor = population_hrv_stats.get("mean_age", 30) / 30
    self.sdnn_threshold = 50 * age_factor  # SDNN decreases with age
    self.rmssd_threshold = 25 * age_factor

    # Store calibration for interpretability
    self.calibration_log.append({
        "timestamp": datetime.now().isoformat(),
        "population_stats": population_hrv_stats,
        "adjusted_thresholds": {
            "sdnn": self.sdnn_threshold,
            "rmssd": self.rmssd_threshold
        }
    })
```

#### 4. Context-Aware Report Generation

Claude Opus 4.5 adapts its report interpretations based on accumulated context:

```python
def generate_adaptive_interpretation(self, features: dict, history: list) -> str:
    """Generate interpretation that considers historical context."""
    context = f"""
    Current HRV metrics: {json.dumps(features)}

    Historical trend (last 5 analyses):
    {json.dumps(history[-5:], indent=2)}

    Consider: Is this a change from baseline? Are there concerning trends?
    Adapt the interpretation based on whether this is a first-time or returning user.
    """

    response = self.client.messages.create(
        model="claude-opus-4-5-20251101",
        max_tokens=1024,
        messages=[{"role": "user", "content": context}]
    )
    return response.content[0].text
```

#### Learning Limitations

- **No online learning during inference:** The classifier is not updated during real-time analysis
- **Human-in-the-loop required:** Model retraining requires validated labels from domain experts
- **Prompt refinements are session-based:** Learned improvements reset between deployments unless persisted

## Results

### Classification Performance on SWELL-KW Test Set

The model was evaluated on held-out subjects S22-S25 (4 subjects, ~800 analysis windows):

| Metric | Value |
|--------|-------|
| **Accuracy** | 78.4% |
| **Sensitivity** (Stress detection) | 81.2% |
| **Specificity** (Neutral detection) | 74.8% |
| **F1-Score** | 0.79 |
| **AUC-ROC** | 0.84 |

### Per-Condition Performance

| Condition | Precision | Recall | Support |
|-----------|-----------|--------|---------|
| Neutral (baseline) | 0.75 | 0.75 | 267 |
| Time pressure | 0.82 | 0.84 | 289 |
| Interruptions | 0.78 | 0.79 | 244 |

### Feature Importance

Top HRV features for stress/fatigue classification (Random Forest importance):

1. **LF/HF ratio** (0.24) - Sympathovagal balance indicator
2. **RMSSD** (0.19) - Parasympathetic activity marker
3. **SDNN** (0.17) - Overall HRV variability
4. **LF power** (0.15) - Sympathetic + baroreflex activity
5. **pNN50** (0.14) - Vagal tone indicator
6. **HF power** (0.11) - Parasympathetic activity

### Processing Performance

| Metric | Value |
|--------|-------|
| Average processing time (3-min window) | 2.8 seconds |
| Claude API latency (orchestration) | 1.2 seconds |
| Report generation (with AI interpretation) | 4.5 seconds |
| Total end-to-end pipeline | 8.5 seconds |

### Cross-Dataset Validation (WESAD)

To assess generalizability, we tested the SWELL-trained model on WESAD data:

| Metric | WESAD (Transfer) |
|--------|------------------|
| Accuracy | 71.2% |
| AUC-ROC | 0.76 |

The performance drop (~7%) is expected due to different stress induction protocols and recording equipment.

## Discussion

### Interpretation of Results

The 78.4% accuracy on the SWELL-KW test set aligns with published benchmarks for HRV-based stress detection. The LF/HF ratio emerged as the most discriminative feature, consistent with its established role as a marker of sympathovagal balance—stress shifts autonomic control toward sympathetic dominance, increasing this ratio.

The higher sensitivity (81.2%) compared to specificity (74.8%) indicates the system is better at detecting stress than confirming relaxation. This asymmetry is acceptable for screening applications where missing stressed individuals has higher cost than false positives.

Time pressure conditions showed the best classification performance (82% precision, 84% recall), likely because this stressor produces more consistent physiological responses than interruptions, which vary in intensity and timing.

### Role of the AI Orchestrator

Claude Opus 4.5 as the orchestrator provided several advantages:
1. **Natural language interface:** Users can request analysis in plain English
2. **Adaptive error handling:** The agent recognizes when signal quality is poor and adjusts processing parameters
3. **Interpretable reports:** AI-generated Discussion and Conclusion sections contextualize metrics for non-experts

The 1.2-second API latency is acceptable for batch processing but may need optimization for real-time monitoring applications.

### Challenges

1. **Inter-subject variability:** HRV baselines vary significantly between individuals. Subject-wise data splitting helped ensure the model generalizes, but personalized baseline calibration would improve accuracy.
2. **Label ambiguity in SWELL-KW:** Self-reported stress via NASA-TLX may not perfectly align with physiological stress responses.
3. **Motion artifacts:** Some SWELL-KW recordings contained movement noise during typing tasks, requiring robust filtering.

### Limitations

- **Dataset scope:** SWELL-KW contains only 25 young, healthy office workers; results may not generalize to elderly, clinical, or athletic populations
- **Binary stress model:** Real-world fatigue exists on a spectrum; our binary classifier simplifies this complexity
- **No temporal modeling:** Current implementation treats each window independently; incorporating temporal patterns (e.g., LSTM) could improve detection
- **Medication effects:** HRV is affected by beta-blockers, caffeine, and other substances not controlled in SWELL-KW
- **Cross-dataset performance:** The 7% accuracy drop on WESAD highlights domain shift challenges

### Lessons Learned

- **Agent architecture value:** The Claude-orchestrated pipeline significantly reduced development time by automating tool coordination and error recovery
- **Feature engineering still matters:** Despite end-to-end learning trends, interpretable HRV features (SDNN, RMSSD, LF/HF) remain effective and clinically meaningful
- **Subject-wise evaluation is essential:** Random train/test splits overestimate performance by allowing data leakage across subjects
- **AI-generated interpretations require validation:** Claude's report text is fluent but should be reviewed by domain experts before clinical use

## Conclusion

We successfully developed an AI agent system for automated HRV-based stress and fatigue detection, achieving 78.4% accuracy on the SWELL-KW test set. The system demonstrates how agentic AI—specifically Claude Opus 4.5 as an orchestrator—can integrate ECG signal processing, HRV feature extraction, machine learning classification, and natural language report generation into a cohesive, automated workflow.

Key contributions:
1. **End-to-end pipeline:** From raw ECG to interpretable PDF report in under 9 seconds
2. **Subject-wise generalization:** Validated on held-out subjects to ensure real-world applicability
3. **AI-enhanced interpretation:** Claude Opus 4.5 generates contextualized Discussion and Conclusion sections that explain metrics in clinical terms
4. **Modular architecture:** Each component (Loader, Processor, Extractor, Classifier, Reporter) can be independently tested, debugged, and improved

Future work directions:
- **Personalized baselines:** Incorporate individual resting HRV to improve classification
- **Multi-class prediction:** Distinguish between stress types (time pressure vs. interruptions) rather than binary classification
- **Temporal modeling:** Use sequence models (LSTM, Transformer) to capture HRV dynamics over time
- **Real-time deployment:** Optimize for streaming ECG analysis with sub-second latency
- **Broader validation:** Test on diverse populations including clinical and elderly subjects

## References

1. Task Force of the European Society of Cardiology and the North American Society
   of Pacing and Electrophysiology. (1996). Heart rate variability: standards of measurement, physiological interpretation and clinical use. Circulation, 93(5), 1043-1065. PMID: 8598068.
2. Pan, J., & Tompkins, W. J. (1985). A real-time QRS detection algorithm.
   IEEE Transactions on Biomedical Engineering, 32(3), 230-236. doi: 10.1109/TBME.1985.325532.


```

---

## Tips for Writing Your Report

### Technical Writing Guidelines

1. **Be precise:** Use specific numbers, methods, and results
2. **Explain your understanding:** Don't just describe what—explain why
3. **Use diagrams:** Architecture diagrams improve clarity
4. **Cite sources:** Reference papers, documentation, tutorials used
5. **Be honest about limitations:** Acknowledging problems shows maturity

### Common Mistakes to Avoid

- Copying text directly from teammates without understanding
- Vague descriptions ("we processed the data")
- Missing technical details (parameters, algorithms, tools)
- No results or evaluation
- Exceeding reasonable length without adding value

---

## Submission Checklist

Before submitting, verify:

- [ ] File named correctly: `YYYY-FamilyName-FirstName.md`
- [ ] Only ASCII characters in filename
- [ ] License declaration included
- [ ] All required sections present
- [ ] Technical content is accurate
- [ ] Your own writing (not copied from teammates)
- [ ] No personally identifiable information (PII)
- [ ] Proofread for errors
